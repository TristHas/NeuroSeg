{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # The code is in the parent folder\n",
    "from segmentation.irsunet import IRSUNet\n",
    "from segmentation.data.data import get_igaku_dendrite_dataset\n",
    "from segmentation.utils_000 import Monitor, experiment\n",
    "from segmentation.Imodules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root   = \"/home/tristan/workspace/Koyama/data/new_datasetB/\"\n",
    "fov    = (64, 128, 128) #2:1:1\n",
    "num_workers = 2\n",
    "val_freq = 1000\n",
    "niter    = 200000\n",
    "nvalrun  = 20\n",
    "skip_invert = False\n",
    "invert = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background (Non-sparse, No Long range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 1\n",
    "sparse = False\n",
    "\n",
    "exp_name = \"Igakubu_bg\"\n",
    "log_base = \"./outputs/log/\" + exp_name\n",
    "mod_base = \"./outputs/model/\" + exp_name\n",
    "\n",
    "dst = [(0,0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "train_ds, test_ds = get_igaku_dendrite_dataset(root, fov, num_workers, dst, sparse)\n",
    "logdir  = log_base        \n",
    "monitor = Monitor(logdir, False, False, False)\n",
    "model   = IRSUNet(len(dst), invert=invert, skip_invert=skip_invert).cuda(device)\n",
    "opt     = torch.optim.Adam(model.parameters())\n",
    "loss_fn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [36:55:43<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "experiment(model, opt, train_ds, test_ds, monitor, val_freq=val_freq, niter=niter, nvalrun=nvalrun, device=device, loss_fn=loss_fn)\n",
    "torch.save(model.state_dict(), mod_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "train_ds, test_ds = get_igaku_dendrite_dataset(root, fov, num_workers, dst, sparse)\n",
    "train_ds.ds.a(train_ds.ds.lbl)[0].shape\n",
    "plt.imshow(train_ds.ds.a(train_ds.ds.lbl)[0][0,0,:,:])\n",
    "plt.imshow(train_ds.ds.lbl[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Long Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "sparse = False\n",
    "exp_name = \"Igakubu_LRandBG\"\n",
    "log_base = \"./outputs/log/\" + exp_name\n",
    "mod_base = \"./outputs/model/\" + exp_name\n",
    "\n",
    "default_dst = list()\n",
    "default_dst.append((0,0,0))\n",
    "default_dst.append((0,0,1))\n",
    "default_dst.append((0,1,0))\n",
    "default_dst.append((1,0,0))\n",
    "\n",
    "default_dst.append((0,0,4))\n",
    "default_dst.append((0,4,0))\n",
    "default_dst.append((2,0,0))\n",
    "\n",
    "default_dst.append((0,0,8))\n",
    "default_dst.append((0,8,0))\n",
    "default_dst.append((4,0,0))\n",
    "\n",
    "default_dst.append((0,0,32))\n",
    "default_dst.append((0,32,0))\n",
    "default_dst.append((16,0,0))\n",
    "\n",
    "dst = default_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "train_ds, test_ds = get_igaku_dendrite_dataset(root, fov, num_workers, dst, sparse)\n",
    "logdir  = log_base        \n",
    "monitor = Monitor(logdir, False, False, False)\n",
    "model   = IRSUNet(len(dst), invert=invert, skip_invert=skip_invert).cuda(device)\n",
    "opt     = torch.optim.Adam(model.parameters())\n",
    "loss_fn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [36:55:43<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "experiment(model, opt, train_ds, test_ds, monitor, val_freq=val_freq, niter=niter, nvalrun=nvalrun, device=device, loss_fn=loss_fn)\n",
    "torch.save(model.state_dict(), mod_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rinkaku (Sparse Long-range Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "sparse = True\n",
    "\n",
    "exp_name = \"Igakubu_Sparse\"\n",
    "log_base = \"./outputs/log/\" + exp_name\n",
    "mod_base = \"./outputs/model/\" + exp_name\n",
    "\n",
    "default_dst = list()\n",
    "default_dst.append((0,0,1))\n",
    "default_dst.append((0,1,0))\n",
    "default_dst.append((1,0,0))\n",
    "\n",
    "default_dst.append((0,0,4))\n",
    "default_dst.append((0,4,0))\n",
    "default_dst.append((2,0,0))\n",
    "\n",
    "default_dst.append((0,0,8))\n",
    "default_dst.append((0,8,0))\n",
    "default_dst.append((4,0,0))\n",
    "\n",
    "default_dst.append((0,0,32))\n",
    "default_dst.append((0,32,0))\n",
    "default_dst.append((16,0,0))\n",
    "\n",
    "dst = default_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "train_ds, test_ds = get_igaku_dendrite_dataset(root, fov, num_workers, dst, sparse)\n",
    "logdir  = log_base        \n",
    "monitor = Monitor(logdir, False, False, False)\n",
    "model   = IRSUNet(len(dst), invert=invert, skip_invert=skip_invert).cuda(device)\n",
    "opt     = torch.optim.Adam(model.parameters())\n",
    "loss_fn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "experiment(model, opt, train_ds, test_ds, monitor, val_freq=val_freq, niter=niter, nvalrun=nvalrun, device=device, loss_fn=loss_fn)\n",
    "torch.save(model.state_dict(), mod_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
